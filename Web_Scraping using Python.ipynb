{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1597d14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Web scraping using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555d2b92",
   "metadata": {},
   "source": [
    "What is Web Scraping and How to Use It?\n",
    "Suppose you want some information from a website? Let’s say a paragraph on Donald Trump! What do you do? Well, you can copy and paste the information from Wikipedia to your own file. But what if you want to get large amounts of information from a website as quickly as possible? Such as large amounts of data from a website to train a Machine Learning algorithm? In such a situation, copy and paste will not work! And that’s when you’ll need to use Web Scraping. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0484f464",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e29e979",
   "metadata": {},
   "source": [
    "Web Scraping is an automatic method of obtaining the large amounts of data in structured format either in a database or spreadsheetand this can be used by different applications.There are some websites which is not advanced and to pull out information we can use web scraping to bring out the data we need in a structured format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66e90e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How a web scraper work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c0c7a8",
   "metadata": {},
   "source": [
    "Web Scrapers can extract all the data on particular sites or the specific data that a user wants. Ideally, it’s best if you specify the data you want so that the web scraper only extracts that data quickly. For example, you might want to scrape an Amazon page for the types of juicers available, but you might only want the data about the models of different juicers and not the customer reviews. \n",
    "\n",
    "So, when a web scraper needs to scrape a site, first the URLs are provided. Then it loads all the HTML code for those sites and a more advanced scraper might even extract all the CSS and Javascript elements as well. Then the scraper obtains the required data from this HTML code and outputs this data in the format specified by the user. Mostly, this is in the form of an Excel spreadsheet or a CSV file, but the data can also be saved in other formats, such as a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abd02826",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What web scraping is used for?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3931f0",
   "metadata": {},
   "source": [
    "1. Price Monitoring\n",
    "Web Scraping can be used by companies to scrap the product data for their products and competing products as well to see how it impacts their pricing strategies. Companies can use this data to fix the optimal pricing for their products so that they can obtain maximum revenue.\n",
    "\n",
    "2. Market Research\n",
    "Web scraping can be used for market research by companies. High-quality web scraped data obtained in large volumes can be very helpful for companies in analyzing consumer trends and understanding which direction the company should move in the future. \n",
    "\n",
    "3. News Monitoring\n",
    "Web scraping news sites can provide detailed reports on the current news to a company. This is even more essential for companies that are frequently in the news or that depend on daily news for their day to day functioning. After all, news reports can make or break a company in a single day!\n",
    "\n",
    "4. Sentiment Analysis\n",
    "If companies want to understand the general sentiment for their products among their consumers, then Sentiment Analysis is a must. Companies can use web scraping to collect data from social media websites such as Facebook and Twitter as to what the general sentiment about their products is. This will help them in creating products that people desire and moving ahead of their competition.\n",
    "\n",
    "5. Email Marketing\n",
    "Companies can also use Web scraping for email marketing. They can collect Email ID’s from various sites using web scraping and then send bulk promotional and marketing Emails to all the people owning these Email ID’s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21a91b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f99ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6db013f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries used in python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fe9e3f",
   "metadata": {},
   "source": [
    "1.BeautifulSoup - which is used for pulling out the data from html or xml files.it provides simple way of navigating and searching.\n",
    "2. Requests - which is used sending and receiving the http content\n",
    "3.selenium- from selenium import webdriver\n",
    "works as requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f9f63c",
   "metadata": {},
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url='https://www.thewhiskyexchange.com/c/35/japanese-whisky'\n",
    "\n",
    "header={'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36'}\n",
    "\n",
    "baseurl=\"https://www.thewhiskeyexchange.com/\"\n",
    "r=requests.get(url)\n",
    "htmlContent=r.content\n",
    "#print(htmlContent)\n",
    "soup=BeautifulSoup(htmlContent,'html.parser')\n",
    "#print(soup)\n",
    "\n",
    "\n",
    "container=soup.find_all('section', class_='js-filter-products')\n",
    "#print(container)\n",
    "#printing the links of every product\n",
    "\n",
    "productslinks=[]\n",
    "for item in container:\n",
    "  for link in item.find_all('a',href=True):\n",
    "      productslinks.append(baseurl + link['href'])\n",
    "        \n",
    "        \n",
    "#print(productslinks)\n",
    "\n",
    "#testlink='https://www.thewhiskyexchange.com/p/37326/akashi-red'\n",
    "\n",
    "whiskylist=[]\n",
    "for link in productslinks:\n",
    "   r=requests.get(link,headers=header,verify=False)\n",
    "   soup=BeautifulSoup(r.content,'html.parser')\n",
    "   name=soup.find('h1',class_='product-main__name').text.strip()\n",
    "   rating=soup.find('span',class_='review-overview__rating star-rating star-rating--40').text.strip()\n",
    "   price=soup.find('p',class_='product-action__price').text.strip()\n",
    "   whisky={'products':name,\n",
    "        'rating': rating,\n",
    "        'price': price}\n",
    "\n",
    "   whiskylist.append(whisky)\n",
    "   \n",
    "   \n",
    "df=pd.DataFrame(whiskylist)\n",
    "print(df.head())\n",
    "\n",
    "#export the data into csv\n",
    "df.to_csv('ProductDetails.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a52fb3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
